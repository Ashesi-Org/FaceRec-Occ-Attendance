{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "40yf2kgedFz4",
        "1wkS-n47dFz9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries"
      ],
      "metadata": {
        "collapsed": false,
        "id": "40yf2kgedFz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c29kAjXxdm8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "id": "EdAVYCRGd9Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "detector = MTCNN()"
      ],
      "metadata": {
        "id": "EhjkkvWzdFz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation"
      ],
      "metadata": {
        "collapsed": false,
        "id": "_gXzTHq2dFz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1wkS-n47dFz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def face_augmentation(path):\n",
        "    datagen = ImageDataGenerator(\n",
        "            rotation_range = 15,\n",
        "            shear_range = 0.2,\n",
        "            zoom_range = 0.35,\n",
        "            horizontal_flip = True,\n",
        "            brightness_range = (0.5, 1.25))\n",
        "\n",
        "    image_directory = path\n",
        "    SIZE = 224\n",
        "    dataset = []\n",
        "    my_images = os.listdir(image_directory)\n",
        "    for i, image_name in enumerate(my_images):\n",
        "      print(image_name)\n",
        "      if image_name.split('.')[-1] == 'jpg' or image_name.split('.')[-1] == 'jpeg':\n",
        "          image = io.imread(image_directory + image_name)\n",
        "          try:\n",
        "            image = Image.fromarray(image, 'RGB')\n",
        "            image = image.resize((SIZE,SIZE))\n",
        "            image = np.array(image)\n",
        "            #image = image.reshape((SIZE, SIZE, 1))\n",
        "            dataset.append(np.array(image))\n",
        "          except:\n",
        "            image = Image.fromarray(image, 'L')\n",
        "            image = image.resize((SIZE,SIZE))\n",
        "            image = np.array(image)\n",
        "            image = image.reshape((SIZE, SIZE, 1))\n",
        "            dataset.append(np.array(image))\n",
        "\n",
        "    x = np.array(dataset)\n",
        "    i = 0\n",
        "    for batch in datagen.flow(x, batch_size=16,\n",
        "                              save_to_dir= path,\n",
        "                              save_prefix='AU',\n",
        "                              save_format='jpg'):\n",
        "        i += 1\n",
        "        if i > 4 :\n",
        "            break"
      ],
      "metadata": {
        "id": "rQaEHmfvdFz-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joe.jpg\n"
          ]
        }
      ],
      "source": [
        "train_path = '/content/drive/MyDrive/Database'\n",
        "\n",
        "for d in os.listdir(train_path):\n",
        "  p = train_path + '/' + d + '/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGM4Cp7CdFz_",
        "outputId": "fc025bef-8eba-4a91-ab52-5a3f46df5525"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detection Phase"
      ],
      "metadata": {
        "collapsed": false,
        "id": "nzNJYguKdFz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class FaceDetection:\n",
        "    def __init__(self, directory):\n",
        "        self.directory = directory\n",
        "        self.target_size = (160,160)\n",
        "        self.X = []\n",
        "        self.Y = []\n",
        "        self.detector = MTCNN()\n",
        "\n",
        "    def extract_face(self, filename):\n",
        "        _image = cv.imread(filename)\n",
        "        _image = cv.cvtColor(_image, cv.COLOR_BGR2RGB)\n",
        "        node_x,node_y,node_w,node_h = self.detector.detect_faces(_image)[0]['box']\n",
        "        node_x,node_y = abs(node_x), abs(node_y)\n",
        "        face = _image[node_y:node_y+node_h, node_x:node_x+node_w]\n",
        "        face_arr = cv.resize(face, self.target_size)\n",
        "        return face_arr\n",
        "\n",
        "    def load_faces(self, dir):\n",
        "        extracted_faces = []\n",
        "        for im_name in os.listdir(dir):\n",
        "            try:\n",
        "                path = dir + im_name\n",
        "                single_face = self.extract_face(path)\n",
        "                extracted_faces.append(single_face)\n",
        "            except:\n",
        "                print(\"couldn't detect\")\n",
        "                pass\n",
        "        return extracted_faces\n",
        "\n",
        "    def load_classes(self):\n",
        "        for sub_dir in os.listdir(self.directory):\n",
        "            path = self.directory +'/'+ sub_dir+'/'\n",
        "            FACES = self.load_faces(path)\n",
        "            print(path)\n",
        "            labels = [sub_dir for _ in range(len(FACES))]\n",
        "            print(f\"Loaded successfully: {len(labels)}\")\n",
        "            self.X.extend(FACES)\n",
        "            self.Y.extend(labels)\n",
        "        return np.asarray(self.X), np.asarray(self.Y)\n",
        "\n",
        "    def plot_images(self):\n",
        "        plt.figure(figsize=(18,16))\n",
        "        for _index,face in enumerate(self.X):\n",
        "            cols = 3\n",
        "            rows = len(self.Y) // cols + 1\n",
        "            plt.subplot(rows, cols, _index + 1)\n",
        "            plt.imshow(face)\n",
        "            plt.axis('off')"
      ],
      "metadata": {
        "id": "4ZjS6ekRdFz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "faces = FaceDetection(r\"/content/drive/MyDrive/Database\")\n",
        "X, Y = faces.load_classes()"
      ],
      "metadata": {
        "id": "MR9SwNQSdF0A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,18))\n",
        "for n,image in enumerate(X):\n",
        "    num_cols = 6\n",
        "    num_rows = len(Y) // num_cols + 1\n",
        "    plt.subplot(num_rows, num_cols, n + 1)\n",
        "    plt.title(f'{Y[n]}')\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "kFFKaZoxdF0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction"
      ],
      "metadata": {
        "id": "weWAFMYI25dB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_facenet"
      ],
      "metadata": {
        "id": "jy27JIZYfssp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_facenet import FaceNet\n",
        "embedder = FaceNet()\n",
        "\n",
        "def get_embedding(face_image):\n",
        "  face_img = face_image.astype('float32') # 3D(160x160x3)\n",
        "  face_img = np.expand_dims(face_img, axis=0) \n",
        "  # 4D (None x 160x160x3)\n",
        "  yhat= embedder.embeddings(face_img)\n",
        "  return yhat[0] # 512D image (1x1x512)"
      ],
      "metadata": {
        "id": "ygTGOAKE3Esn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDED_X = []\n",
        "\n",
        "for img in X:\n",
        "    EMBEDDED_X.append(get_embedding(img))\n",
        "\n",
        "EMBEDDED_X = np.asarray(EMBEDDED_X)"
      ],
      "metadata": {
        "id": "mF0XbnbY4fhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez_compressed('face_embeddings.npz', EMBEDDED_X, Y)"
      ],
      "metadata": {
        "id": "sr9TG9hw41DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {
        "id": "ZS0gz_2s6wv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "Y = encoder.transform(Y)\n",
        "\n",
        "# table for no encoder and svm on embeddings\n",
        "Y"
      ],
      "metadata": {
        "id": "o6ipBuW26sny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(EMBEDDED_X, Y, shuffle=True, random_state=17)"
      ],
      "metadata": {
        "id": "XszYpqu57TrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svm = SVC(kernel='linear', probability=True)\n",
        "svm.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "9awbOomN7iZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(criterion='gini')\n",
        "decision_tree.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "1tpyoI2adF0G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "decision_tree_test = decision_tree.predict(X_test)\n",
        "decision_tree_train = decision_tree.predict(X_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Y_train, decision_tree_train) * 100, accuracy_score(Y_test, decision_tree_test) * 100"
      ],
      "metadata": {
        "id": "QUmxy_NGdF0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_train = svm.predict(X_train)\n",
        "svm_test = svm.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(Y_train, svm_train) * 100, accuracy_score(Y_test, svm_test) * 100"
      ],
      "metadata": {
        "id": "9sZVkbu07pdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        " \n",
        "cm = confusion_matrix(Y_test,decision_tree_test)\n",
        "cm"
      ],
      "metadata": {
        "id": "XtZ0vyo6AKuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "px.imshow(cm, labels=dict(x=\"Prediction\", y=\"Truth\"), color_continuous_scale=\"Inferno\", text_auto=True)"
      ],
      "metadata": {
        "id": "6BxskeBd9LVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "y_score = svm.predict_proba(X_test)[:, 1]\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(Y_train, y_score)\n",
        "\n",
        "fig = px.area(\n",
        "    x=fpr, y=tpr,\n",
        "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
        "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
        "    width=700, height=500\n",
        ")\n",
        "fig.add_shape(\n",
        "    type='line', line=dict(dash='dash'),\n",
        "    x0=0, x1=1, y0=0, y1=1\n",
        ")\n",
        "\n",
        "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "fig.update_xaxes(constrain='domain')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "DuBc5ZCV__H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "bWE0RH6CsF5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_test(directory):\n",
        "    res = []\n",
        "    nms = []\n",
        "    actual = []\n",
        "    correct = 0\n",
        "    for sub_dir in os.listdir(directory):\n",
        "        path = directory + '/' + sub_dir + '/'\n",
        "        actual.append(sub_dir)\n",
        "        for im_name in os.listdir(path):\n",
        "            f_path = path +'/'+ im_name\n",
        "            person = cv.imread(f_path)\n",
        "            print(im_name)\n",
        "            person = cv.cvtColor(person, cv.COLOR_BGR2RGB)\n",
        "            try:\n",
        "                node__x,node__y,node__w,node__h = detector.detect_faces(person)[0]['box']\n",
        "                face = person[node__y:node__y + node__h, node__x:node__x + node__w]\n",
        "                face = cv.resize(face, (160,160))\n",
        "                test_emb = get_embedding(face)\n",
        "                f_pred = svm.predict([test_emb])\n",
        "                res.append(person)\n",
        "                nms.append(encoder.inverse_transform(f_pred)[0])\n",
        "                if sub_dir == encoder.inverse_transform(f_pred)[0]:\n",
        "                    correct += 1\n",
        "            except:\n",
        "                pass\n",
        "    return res, nms, actual, correct\n",
        "\n",
        "def decision_tree_test(directory):\n",
        "    res = []\n",
        "    nms = []\n",
        "    actual = []\n",
        "    correct = 0\n",
        "    for sub_dir in os.listdir(directory):\n",
        "        path = directory + '/' + sub_dir + '/'\n",
        "        actual.append(sub_dir)\n",
        "        for im_name in os.listdir(path):\n",
        "            f_path = path +'/'+ im_name\n",
        "            person = cv.imread(f_path)\n",
        "            print(im_name)\n",
        "            person = cv.cvtColor(person, cv.COLOR_BGR2RGB)\n",
        "            try:\n",
        "                node__x,node__y,node__w,node__h = detector.detect_faces(person)[0]['box']\n",
        "                face = person[node__y:node__y + node__h, node__x:node__x + node__w]\n",
        "                face = cv.resize(face, (160,160))\n",
        "                test_emb = get_embedding(face)\n",
        "                f_pred = svm.predict([test_emb])\n",
        "                res.append(person)\n",
        "                nms.append(encoder.inverse_transform(f_pred)[0])\n",
        "                if sub_dir == encoder.inverse_transform(f_pred)[0]:\n",
        "                    correct += 1\n",
        "            except:\n",
        "                pass\n",
        "    return res, nms, actual, correct"
      ],
      "metadata": {
        "id": "HTkOUEWzq5rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "svm_im = svm_test(r\"/content/drive/MyDrive/Datasets (1)/JAFFE Dataset/val\")"
      ],
      "metadata": {
        "id": "DxyaDI1B1Pqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "%%time\n",
        "decision_tree_im = decision_tree_test(r\"/content/drive/MyDrive/Datasets (1)/JAFFE Dataset/val\")"
      ],
      "metadata": {
        "id": "snSPH3erdF0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_people, svm_names, svm_images, svm_corrects = svm_im[2], svm_im[1], svm_im[0], svm_im[3]\n",
        "[svm_corrects, len(svm_names), svm_corrects/len(svm_names)]"
      ],
      "metadata": {
        "id": "xSt18BwN41gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "decision_tree_people, decision_tree_names, decision_tree_images, decision_tree_corrects = decision_tree_im[2], decision_tree_im[1], decision_tree_im[0], decision_tree_im[3]\n",
        "[decision_tree_corrects, len(decision_tree_names), decision_tree_corrects/len(decision_tree_names)]"
      ],
      "metadata": {
        "id": "xgn4-9j9dF0K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize= (18, 18))\n",
        "for i, img in enumerate(decision_tree_images):\n",
        "  ax = fig.add_subplot(12, 5, i+1)\n",
        "  plt.title(f'{decision_tree_names[i]}')\n",
        "  plt.axis('off')\n",
        "  ax.imshow(img)"
      ],
      "metadata": {
        "id": "38jnaq1OdF0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "#save the model\n",
        "with open('students_model_v1.pkl','wb') as f:\n",
        "    pickle.dump(svm,f)\n"
      ],
      "metadata": {
        "id": "xeQn4NnpVpuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file = '/content/drive/MyDrive/Database/JOE/' \n",
        "ims =[]\n",
        "for im_name in os.listdir(file):\n",
        "  f_path = file +'/'+ im_name\n",
        "  person = cv.imread(f_path)\n",
        "  person = cv.cvtColor(person, cv.COLOR_BGR2RGB)\n",
        "  ims.append(person)\n",
        "\n",
        "fig = plt.figure(figsize= (18, 18))\n",
        "for i, img in enumerate(ims):\n",
        "  ax = fig.add_subplot(1, 6, i+1)\n",
        "  plt.axis('off')\n",
        "  ax.imshow(img)"
      ],
      "metadata": {
        "id": "JA4EOUWVdF0M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLpa0HhB1aWV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}